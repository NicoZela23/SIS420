{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE_iwdR5m6xH"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/028_pytorch_nn/pytorch_nn.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjhgRWO_m6xK"
      },
      "source": [
        "# Pytorch - Redes Neuronales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVNrcQ_5m6xK"
      },
      "source": [
        "En el post [anterior](https://sensioai.com/blog/027_pytorch_intro) hicimos una introducción al framework de `redes neuronales` `Pytorch`. Hablamos de sus tres elementos fundamentales: el objeto `tensor` (similar al `array` de `NumPy`) `autograd` (que nos permite calcular derivadas de manera automáticas) y el soporte GPU. En este post vamos a entrar en detalle en la  funcionalidad que nos ofrece la librería para diseñar redes neuronales de manera flexible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:21:45.471625Z",
          "start_time": "2020-08-15T12:21:45.002765Z"
        },
        "id": "4hnzhQywm6xL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "IqUKyQ9Nm6xM"
      },
      "source": [
        "## Modelos secuenciales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "MDSz2Mbsm6xM"
      },
      "source": [
        "La forma más sencilla de definir una `red neuronal` en `Pytorch` es utilizando la clase `Sequentail`. Esta clase nos permite definir una secuencia de capas, que se aplicarán de manera secuencial (las salidas de una capa serán la entrada de la siguiente). Ésto ya lo conocemos de posts anteriores, ya que es la forma ideal de definir un `Perceptrón Multicapa`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:21:45.486329Z",
          "start_time": "2020-08-15T12:21:45.472624Z"
        },
        "hidden": true,
        "id": "V5KEpUHVm6xN"
      },
      "outputs": [],
      "source": [
        "D_in, H, D_out = 784, 100, 10\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "\n",
        "# D_in, H1, H2, D_out = 784, 100, 50, 10\n",
        "# model = torch.nn.Sequential(\n",
        "#     torch.nn.Linear(D_in, H1),\n",
        "#     torch.nn.ReLU(),\n",
        "#     torch.nn.Linear(H1, H2),\n",
        "#     torch.nn.ReLU(),\n",
        "#     torch.nn.Linear(H2, D_out),\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "8Ea8TfSWm6xO"
      },
      "source": [
        "El modelo anterior es un `MLP` con 784 entradas, 100 neuronas en la capa oculta y 10 salidas. Podemos usar este modelo para hacer un clasificador de imágenes con el dataset MNIST. Pero primero, vamos a ver como podemos calcular las salidas del modelo a partir de unas entradas de ejemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:21:45.502329Z",
          "start_time": "2020-08-15T12:21:45.487329Z"
        },
        "hidden": true,
        "id": "WVB30MPem6xO",
        "outputId": "7b0cbb21-00ae-4da7-d49c-9901660aa928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "outputs = model(torch.randn(64, 784))\n",
        "outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs[0][:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7mk9EVzLeBV",
        "outputId": "9a685670-9f0a-4be0-e1fd-ae01e15980ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.3348, -0.0037,  0.2422,  0.3595,  0.0650,  0.0322, -0.0223,  0.0968,\n",
            "         0.2215, -0.0772], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "I-J9Sa6Qm6xP"
      },
      "source": [
        "Como puedes ver, simplemente le pasamos los inputs al modelo (llamándolo como una función). En este caso, usamos un tensor con 64 vectores de 784 valores. Es importante remarcar que los modelos de `Pytorch` (por lo general) siempre esperan que la primera dimensión sea la dimensión *batch*. Si queremos entrenar esta red en una GPU, es tan sencillo como"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:21:46.777020Z",
          "start_time": "2020-08-15T12:21:45.503329Z"
        },
        "hidden": true,
        "id": "VjtJxIM_m6xQ",
        "outputId": "b5e5af07-908f-4a41-ea2e-4b021cbdfa1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=100, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "ZxmpSqz6m6xQ"
      },
      "source": [
        "Vamos a ver ahora como entrenar este modelo con el dataset MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:05.622262Z",
          "start_time": "2020-08-15T12:21:46.778019Z"
        },
        "hidden": true,
        "id": "OmlXe8Gpm6xR",
        "outputId": "2d47c09e-ba92-40d8-f6cb-55c13ca6fddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((54894, 784), (54894,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Reemplaza 'dataset.csv' con la ruta correcta a tu archivo CSV\n",
        "data = pd.read_csv('Glyphs_updated.csv')\n",
        "\n",
        "# Eliminar todas las columnas con valores NaN\n",
        "data = data.dropna(axis=1)\n",
        "\n",
        "# Llenar los valores faltantes con un valor específico, como cero (0)\n",
        "data = data.fillna(0)\n",
        "\n",
        "Y = data['label']\n",
        "X = data.drop(columns=['label'])\n",
        "\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "X = X.fillna(0)\n",
        "\n",
        "X.shape, Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:05.761911Z",
          "start_time": "2020-08-15T12:22:05.624102Z"
        },
        "hidden": true,
        "id": "BzhE25udm6xR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# normalización y split\n",
        "import numpy as np\n",
        "x_2=np.array(X)\n",
        "y_2= Y\n",
        "\n",
        "\n",
        "# normalización y split\n",
        "\n",
        "X_train =x_2[:36982] / 255.\n",
        "X_test =x_2[17912:] / 255.\n",
        "y_train = y_2[:36982]\n",
        "y_test = y_2[:17912]\n",
        "\n",
        "\n",
        "\n",
        "# X_train, X_test, y_train, y_test = X[:60000] / 255., X[60000:] / 255., Y[:60000].astype(np.float32), Y[60000:].astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:05.777964Z",
          "start_time": "2020-08-15T12:22:05.763102Z"
        },
        "hidden": true,
        "id": "pDJK07Jpm6xR"
      },
      "outputs": [],
      "source": [
        "# función de pérdida y derivada\n",
        "\n",
        "def softmax(x):\n",
        "    return torch.exp(x) / torch.exp(x).sum(axis=-1,keepdims=True)\n",
        "\n",
        "def cross_entropy(output, target):\n",
        "    logits = output[torch.arange(len(output)), target]\n",
        "    loss = - logits + torch.log(torch.sum(torch.exp(output), axis=-1))\n",
        "    loss = loss.mean()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHL3LiGejvr0",
        "outputId": "11959215-a59c-4073-fc65-5677f2365131"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "tZCJjxDZyenK",
        "outputId": "9a070176-1a88-40d9-9041-a83a0cfed8f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       1  2  3  4  5  6  7  8  9  10  ...  775  776  777  778  779  780  781  \\\n",
            "0      0  0  0  0  0  0  0  0  0   0  ...    0    0    0    0    0    0    0   \n",
            "1      0  0  0  0  0  0  0  0  0   0  ...    0    0    0    0    0    0    0   \n",
            "2      0  0  0  0  0  0  0  0  0   0  ...    0    0    0    0    0    0    0   \n",
            "3      0  0  0  0  0  0  0  0  0   0  ...    0    0    0    0    0    0    0   \n",
            "4      0  0  0  0  0  0  0  0  0   0  ...    0    0    0    0    0    0    0   \n",
            "...   .. .. .. .. .. .. .. .. ..  ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "54889  0  0  0  0  0  0  0  0  0   0  ...    0    0    0    0    0    0    0   \n",
            "54890  0  0  0  0  0  0  0  0  0   0  ...    0    0    0    0    0    0    0   \n",
            "54891  0  0  0  0  0  0  0  0  0   0  ...    0    0    0    0    0    0    0   \n",
            "54892  0  0  0  0  0  0  0  0  0   0  ...    0    0    0    0    0    0    0   \n",
            "54893  0  0  0  0  0  0  0  0  0   0  ...    0    0    0    0    0    0    0   \n",
            "\n",
            "       782  783  784  \n",
            "0        0    0    0  \n",
            "1        0    0    0  \n",
            "2        0    0    0  \n",
            "3        0    0    0  \n",
            "4        0    0    0  \n",
            "...    ...  ...  ...  \n",
            "54889    0    0    0  \n",
            "54890    0    0    0  \n",
            "54891    0    0    0  \n",
            "54892    0    0    0  \n",
            "54893    0    0    0  \n",
            "\n",
            "[54894 rows x 784 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:07.268014Z",
          "start_time": "2020-08-15T12:22:05.778966Z"
        },
        "hidden": true,
        "id": "EjdhOJ90m6xS",
        "outputId": "61d88866-ae4d-403e-dd22-04e3e4e5ab53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3a4dd81ac9cc>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-3d5fda269b2f>\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(output, target)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "# convertimos datos a tensores y copiamos en gpu\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_numeric = label_encoder.fit_transform(y_train)\n",
        "\n",
        "X_t = torch.from_numpy(X_train).float().cuda()\n",
        "Y_t = torch.LongTensor(y_train_numeric)\n",
        "\n",
        "# bucle entrenamiento\n",
        "epochs = 100\n",
        "lr = 0.8\n",
        "log_each = 10\n",
        "l = []\n",
        "for e in range(1, epochs + 1):\n",
        "\n",
        "    # forward\n",
        "    y_pred = model(X_t)\n",
        "\n",
        "    # loss\n",
        "    loss = cross_entropy(y_pred, Y_t)\n",
        "    l.append(loss.item())\n",
        "\n",
        "    # ponemos a cero los gradientes\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Backprop (calculamos todos los gradientes automáticamente)\n",
        "    loss.backward()\n",
        "\n",
        "    # update de los pesos\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= lr * param.grad\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "5tCiIuSvm6xT"
      },
      "source": [
        "Como puedes observar en el ejemplo, podemos calcular la salida del modelo con una simple línea. Luego calculamos la función de pérdida, y llamando a la función `backward` `Pytorch` se encarga de calcular las derivadas de la misma con respecto a todos los parámetros del modelo automáticamente (si no queremos acumular estos gradientes, nos aseguramos de llamar a la función `zero_grad` para ponerlos a cero antes de calcularlos). Por útlimo, podemos iterar por los parámetros del modelo aplicando la regla de actualización deseada (en este caso usamos `descenso por gradiente`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:07.312014Z",
          "start_time": "2020-08-15T12:22:07.270016Z"
        },
        "hidden": true,
        "id": "Ufomq0IIm6xT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef752177-01eb-4d52-99bc-64fbcf16c9a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9603015075376884"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate(x):\n",
        "    model.eval()\n",
        "    y_pred = model(x)\n",
        "    y_probas = softmax(y_pred)\n",
        "    return torch.argmax(y_probas, axis=1)\n",
        "\n",
        "y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "sgoJC4nIm6xY"
      },
      "source": [
        "De esta manera, tenemos mucha flexibilidad para definir nuestras redes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IanjDRkm6xa"
      },
      "source": [
        "## Resumen"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "233.594px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}